{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "spHPfunsclVS",
    "outputId": "79aa678d-08be-4733-9132-58dec7032d55",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53MjPBnLC29m",
    "outputId": "f0a660c9-9661-40fa-b0ef-f3ce87310ee6"
   },
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdRcP_ORCzPv",
    "outputId": "ff500f7b-08e2-47a1-80c5-7098250472b7"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image, ImageFile\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "import torch.nn.functional as F\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "khf3ODvQDMsn"
   },
   "outputs": [],
   "source": [
    "dataset_path = r\"D:\\imagecol\\new\"\n",
    "BATCH_SIZE = 4\n",
    "INPUT_SHAPE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vm3ExHorDTGm"
   },
   "outputs": [],
   "source": [
    "def DisplayImages(imagepaths):\n",
    "    num_images = len(imagepaths)\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 6))\n",
    "    for i, ax in enumerate(axes):\n",
    "        img = Image.open(imagepaths[i])\n",
    "        # print(img.mode)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "0w8yAMfjDXdu",
    "outputId": "ee5599a0-09e9-4fc9-e290-a263a55367c8"
   },
   "outputs": [],
   "source": [
    "images = os.listdir(dataset_path)\n",
    "rdx = np.random.randint(0, len(images), 5)\n",
    "ipath = [dataset_path+'/' + images[i] for i in rdx]\n",
    "\n",
    "DisplayImages(ipath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "id": "YDp_l7RvDcj-",
    "outputId": "98221947-beec-44fa-f4b8-5a975e6cb22c"
   },
   "outputs": [],
   "source": [
    "train_idx = int(len(images) * 0.8)\n",
    "test_idx = int(len(images) * 0.2)\n",
    "rand_idx = np.random.permutation(len(images))\n",
    "train_idxs = rand_idx[:train_idx]\n",
    "test_idxs = rand_idx[train_idx:]\n",
    "\n",
    "train_images = [os.path.join(dataset_path,images[i]) for i in train_idxs]\n",
    "test_images = [os.path.join(dataset_path,images[i]) for i in test_idxs]\n",
    "\n",
    "# print(train_idxs)\n",
    "print(train_images[0])\n",
    "print(len(train_images), len(test_images))\n",
    "DisplayImages(train_images[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkcJWf--DmXv"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, paths, split=\"train\"):\n",
    "        if split == 'train':\n",
    "            self.transforms = transforms.Compose(\n",
    "                [\n",
    "                    transforms.Resize((INPUT_SHAPE, INPUT_SHAPE), Image.BICUBIC),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                ]\n",
    "            )\n",
    "        elif split == \"val\":\n",
    "            self.transforms = transforms.Resize((INPUT_SHAPE, INPUT_SHAPE), Image.BICUBIC)\n",
    "        self.split = split\n",
    "        self.paths = paths\n",
    "        self.size = BATCH_SIZE\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.paths[idx]).convert(\"RGB\")\n",
    "        image = self.transforms(image)\n",
    "        img = np.array(image)\n",
    "        img_lab = rgb2lab(img).astype(\"float32\")\n",
    "        img_lab = transforms.ToTensor()(img_lab)\n",
    "        # print(img_lab.shape)\n",
    "        # print(img_lab)\n",
    "        L = img_lab[[0],...]/50.0 - 1.0\n",
    "        ab = img_lab[[1,2], ...]/110.0\n",
    "        return {\"L\": L, \"ab\":ab}\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "def make_dataloader(batch=8, pin_memory = True, **kwargs):\n",
    "    dataset = CustomDataset(**kwargs)\n",
    "    dataloader = DataLoader(dataset, batch_size = batch, pin_memory = pin_memory)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6idN1zaqDn-W",
    "outputId": "5ec3d7b0-9735-4922-8e2c-4ae5d456978f"
   },
   "outputs": [],
   "source": [
    "traindl = make_dataloader(paths = train_images, split = \"train\")\n",
    "testdl = make_dataloader(paths = test_images, split = \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7dDS-gV6DstV"
   },
   "outputs": [],
   "source": [
    "data = next(iter(traindl))\n",
    "# print(data[\"ab\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "Kr0ww-dOD2H-",
    "outputId": "1c979db2-9b69-4950-edd2-a0d3e49cd4b2"
   },
   "outputs": [],
   "source": [
    "grid_image = make_grid(data[\"L\"], nrow=4, padding=2, pad_value=1)\n",
    "plt.imshow(grid_image.permute(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UcBBQ1yAFxoW",
    "outputId": "7c268715-ca35-4064-b674-35f90e0a054f"
   },
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    for j in range(2):\n",
    "        plt.subplot(1, 2, j + 1)\n",
    "        plt.imshow(data[\"ab\"][i, j])\n",
    "        plt.title(f'Channel {j+1}')\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(f'Image {i+1}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qyd1i7wBrLp7"
   },
   "outputs": [],
   "source": [
    "# # class ASSP(nn.Module):\n",
    "# #   def __init__(self,in_channels,out_channels = 256):\n",
    "# #     super(ASSP,self).__init__()\n",
    "\n",
    "\n",
    "# #     self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "# #     self.conv1 = nn.Conv2d(in_channels = in_channels,\n",
    "# #                           out_channels = out_channels,\n",
    "# #                           kernel_size = 1,\n",
    "# #                           padding = 0,\n",
    "# #                           dilation=1,\n",
    "# #                           bias=False)\n",
    "\n",
    "# #     self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "# #     self.conv2 = nn.Conv2d(in_channels = in_channels,\n",
    "# #                           out_channels = out_channels,\n",
    "# #                           kernel_size = 3,\n",
    "# #                           stride=1,\n",
    "# #                           padding = 6,\n",
    "# #                           dilation = 6,\n",
    "# #                           bias=False)\n",
    "\n",
    "# #     self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "# #     self.conv3 = nn.Conv2d(in_channels = in_channels,\n",
    "# #                           out_channels = out_channels,\n",
    "# #                           kernel_size = 3,\n",
    "# #                           stride=1,\n",
    "# #                           padding = 12,\n",
    "# #                           dilation = 12,\n",
    "# #                           bias=False)\n",
    "\n",
    "# #     self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "# #     self.conv4 = nn.Conv2d(in_channels = in_channels,\n",
    "# #                           out_channels = out_channels,\n",
    "# #                           kernel_size = 3,\n",
    "# #                           stride=1,\n",
    "# #                           padding = 18,\n",
    "# #                           dilation = 18,\n",
    "# #                           bias=False)\n",
    "\n",
    "# #     self.bn4 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "# #     self.conv5 = nn.Conv2d(in_channels = in_channels,\n",
    "# #                           out_channels = out_channels,\n",
    "# #                           kernel_size = 1,\n",
    "# #                           stride=1,\n",
    "# #                           padding = 0,\n",
    "# #                           dilation=1,\n",
    "# #                           bias=False)\n",
    "\n",
    "# #     self.bn5 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "# #     self.convf = nn.Conv2d(in_channels = out_channels * 5,\n",
    "# #                           out_channels = out_channels,\n",
    "# #                           kernel_size = 1,\n",
    "# #                           stride=1,\n",
    "# #                           padding = 0,\n",
    "# #                           dilation=1,\n",
    "# #                           bias=False)\n",
    "\n",
    "# #     self.bnf = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "# #     self.adapool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "\n",
    "# #   def forward(self,x):\n",
    "# #     x1 = self.conv1(x)\n",
    "# #     x1 = self.bn1(x1)\n",
    "# #     x1 = self.relu(x1)\n",
    "\n",
    "# #     x2 = self.conv2(x)\n",
    "# #     x2 = self.bn2(x2)\n",
    "# #     x2 = self.relu(x2)\n",
    "\n",
    "# #     x3 = self.conv3(x)\n",
    "# #     x3 = self.bn3(x3)\n",
    "# #     x3 = self.relu(x3)\n",
    "\n",
    "# #     x4 = self.conv4(x)\n",
    "# #     x4 = self.bn4(x4)\n",
    "# #     x4 = self.relu(x4)\n",
    "\n",
    "# #     x5 = self.adapool(x)\n",
    "# #     x5 = self.conv5(x5)\n",
    "# #     x5 = self.bn5(x5)\n",
    "# #     x5 = self.relu(x5)\n",
    "# #     x5 = F.interpolate(x5, size = tuple(x4.shape[-2:]), mode='bilinear')\n",
    "\n",
    "# #     x = torch.cat((x1,x2,x3,x4,x5), dim = 1) #channels first\n",
    "# #     x = self.convf(x)\n",
    "# #     x = self.bnf(x)\n",
    "# #     x = self.relu(x)\n",
    "\n",
    "# #     return x\n",
    "\n",
    "\n",
    "\n",
    "class ASSP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=256, final_out_channels=2):\n",
    "        super(ASSP, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # 1x1 convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0, dilation=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # 3x3 convolutions with different dilation rates\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=3, dilation=3, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=6, dilation=6, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=9, dilation=9, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # 1x1 convolution after global average pooling\n",
    "        self.conv5 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.bn5 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Final 1x1 convolution to combine features\n",
    "        self.convf = nn.Conv2d(out_channels * 5, final_out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.bnf = nn.BatchNorm2d(final_out_channels)\n",
    "\n",
    "        # Global average pooling\n",
    "        self.adapool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1x1 convolution\n",
    "        x1 = self.conv1(x)\n",
    "        x1 = self.bn1(x1)\n",
    "        x1 = self.relu(x1)\n",
    "\n",
    "        # 3x3 convolution with dilation 6\n",
    "        x2 = self.conv2(x)\n",
    "        x2 = self.bn2(x2)\n",
    "        x2 = self.relu(x2)\n",
    "\n",
    "        # 3x3 convolution with dilation 12\n",
    "        x3 = self.conv3(x)\n",
    "        x3 = self.bn3(x3)\n",
    "        x3 = self.relu(x3)\n",
    "\n",
    "        # 3x3 convolution with dilation 18\n",
    "        x4 = self.conv4(x)\n",
    "        x4 = self.bn4(x4)\n",
    "        x4 = self.relu(x4)\n",
    "\n",
    "        # Global average pooling, 1x1 convolution, and upsample\n",
    "        x5 = self.adapool(x)\n",
    "        x5 = self.conv5(x5)\n",
    "        x5 = self.bn5(x5)\n",
    "        x5 = self.relu(x5)\n",
    "        x5 = F.interpolate(x5, size=x4.shape[-2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        # Concatenate all feature maps\n",
    "        x = torch.cat((x1, x2, x3, x4, x5), dim=1)\n",
    "\n",
    "        # Final 1x1 convolution\n",
    "        x = self.convf(x)\n",
    "        x = self.bnf(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# import math\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from models.sync_batchnorm.batchnorm import SynchronizedBatchNorm2d\n",
    "\n",
    "# class _ASPPModule(nn.Module):\n",
    "#     def __init__(self, inplanes, planes, kernel_size, padding, dilation, BatchNorm):\n",
    "#         super(_ASPPModule, self).__init__()\n",
    "#         self.atrous_conv = nn.Conv2d(inplanes, planes, kernel_size=kernel_size,\n",
    "#                                             stride=1, padding=padding, dilation=dilation, bias=False)\n",
    "#         self.bn = BatchNorm(planes)\n",
    "#         self.relu = nn.ReLU()\n",
    "\n",
    "#         self._init_weight()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.atrous_conv(x)\n",
    "#         x = self.bn(x)\n",
    "\n",
    "#         return self.relu(x)\n",
    "\n",
    "#     def _init_weight(self):\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Conv2d):\n",
    "#                 torch.nn.init.kaiming_normal_(m.weight)\n",
    "#             elif isinstance(m, SynchronizedBatchNorm2d):\n",
    "#                 m.weight.data.fill_(1)\n",
    "#                 m.bias.data.zero_()\n",
    "#             elif isinstance(m, nn.BatchNorm2d):\n",
    "#                 m.weight.data.fill_(1)\n",
    "#                 m.bias.data.zero_()\n",
    "\n",
    "# class ASPP(nn.Module):\n",
    "#     def __init__(self, backbone, output_stride, BatchNorm):\n",
    "#         super(ASPP, self).__init__()\n",
    "#         if backbone == 'drn':\n",
    "#             inplanes = 512\n",
    "#         elif backbone == 'mobilenet':\n",
    "#             inplanes = 320\n",
    "#         else:\n",
    "#             inplanes = 2048\n",
    "#         if output_stride == 16:\n",
    "#             dilations = [1, 6, 12, 18]\n",
    "#         elif output_stride == 8:\n",
    "#             dilations = [1, 12, 24, 36]\n",
    "#         else:\n",
    "#             raise NotImplementedError\n",
    "\n",
    "#         self.aspp1 = _ASPPModule(inplanes, 256, 1, padding=0, dilation=dilations[0], BatchNorm=BatchNorm)\n",
    "#         self.aspp2 = _ASPPModule(inplanes, 256, 3, padding=dilations[1], dilation=dilations[1], BatchNorm=BatchNorm)\n",
    "#         self.aspp3 = _ASPPModule(inplanes, 256, 3, padding=dilations[2], dilation=dilations[2], BatchNorm=BatchNorm)\n",
    "#         self.aspp4 = _ASPPModule(inplanes, 256, 3, padding=dilations[3], dilation=dilations[3], BatchNorm=BatchNorm)\n",
    "\n",
    "#         self.global_avg_pool = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
    "#                                              nn.Conv2d(inplanes, 256, 1, stride=1, bias=False),\n",
    "#                                              BatchNorm(256),\n",
    "#                                              nn.ReLU())\n",
    "#         self.conv1 = nn.Conv2d(1280, 256, 1, bias=False)\n",
    "#         self.bn1 = BatchNorm(256)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "#         self._init_weight()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x1 = self.aspp1(x)\n",
    "#         x2 = self.aspp2(x)\n",
    "#         x3 = self.aspp3(x)\n",
    "#         x4 = self.aspp4(x)\n",
    "#         x5 = self.global_avg_pool(x)\n",
    "#         x5 = F.interpolate(x5, size=x4.size()[2:], mode='bilinear', align_corners=True)\n",
    "#         x = torch.cat((x1, x2, x3, x4, x5), dim=1)\n",
    "\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.relu(x)\n",
    "\n",
    "#         return self.dropout(x)\n",
    "\n",
    "#     def _init_weight(self):\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Conv2d):\n",
    "#                 # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "#                 # m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "#                 torch.nn.init.kaiming_normal_(m.weight)\n",
    "#             elif isinstance(m, SynchronizedBatchNorm2d):\n",
    "#                 m.weight.data.fill_(1)\n",
    "#                 m.bias.data.zero_()\n",
    "#             elif isinstance(m, nn.BatchNorm2d):\n",
    "#                 m.weight.data.fill_(1)\n",
    "#                 m.bias.data.zero_()\n",
    "\n",
    "\n",
    "# def build_aspp(backbone, output_stride, BatchNorm):\n",
    "#     return ASPP(backbone, output_stride, BatchNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7n2wH8v3Fhl"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "# class ResNet_50 (nn.Module):\n",
    "#   def __init__(self, in_channels = 1, conv1_out = 64):\n",
    "#     super(ResNet_50,self).__init__()\n",
    "\n",
    "#     self.resnet_50 = models.resnet50(pretrained = True)\n",
    "\n",
    "#     self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "# #   def forward(self,x):\n",
    "# #     x = self.relu(self.resnet_50.bn1(self.resnet_50.conv1(x)))\n",
    "# #     x = self.resnet_50.maxpool(x)\n",
    "# #     x = self.resnet_50.layer1(x)\n",
    "# #     x = self.resnet_50.layer2(x)\n",
    "# #     x = self.resnet_50.layer3(x)\n",
    "\n",
    "# #     return x\n",
    "\n",
    "class ResNet_50(nn.Module):\n",
    "    def __init__(self, in_channels=1):\n",
    "        super(ResNet_50, self).__init__()\n",
    "\n",
    "        # Load the pre-trained ResNet-50 model\n",
    "        self.resnet_50 = models.resnet50(pretrained=True)\n",
    "\n",
    "        # Modify the first convolutional layer to accept 1-channel input\n",
    "        self.resnet_50.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        # Use the layers up to the final layer before the fully connected layer\n",
    "        self.resnet_50 = nn.Sequential(*list(self.resnet_50.children())[:-2])\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet_50(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_classes, backbone, BatchNorm):\n",
    "        super(Decoder, self).__init__()\n",
    "        if backbone == 'resnet' or backbone == 'drn':\n",
    "            low_level_inplanes = 256\n",
    "        elif backbone == 'xception':\n",
    "            low_level_inplanes = 128\n",
    "        elif backbone == 'mobilenet':\n",
    "            low_level_inplanes = 24\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.conv1 = nn.Conv2d(low_level_inplanes, 48, 1, bias=False)\n",
    "        self.bn1 = BatchNorm(48)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.last_conv = nn.Sequential(nn.Conv2d(304, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                       BatchNorm(256),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Dropout(0.5),\n",
    "                                       nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                       BatchNorm(256),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Dropout(0.1),\n",
    "                                       nn.Conv2d(256, num_classes, kernel_size=1, stride=1))\n",
    "        self._init_weight()\n",
    "\n",
    "    def forward(self, x, low_level_feat):\n",
    "        low_level_feat = self.conv1(low_level_feat)\n",
    "        low_level_feat = self.bn1(low_level_feat)\n",
    "        low_level_feat = self.relu(low_level_feat)\n",
    "\n",
    "        # Upsample x to match the size of low_level_feat\n",
    "        x = F.interpolate(x, size=(512, 512), mode='bilinear', align_corners=True)\n",
    "        low_level_feat = F.interpolate(low_level_feat, size=(512, 512), mode='bilinear', align_corners=True)\n",
    "\n",
    "        x = torch.cat((x, low_level_feat), dim=1)\n",
    "        x = self.last_conv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "def build_decoder(num_classes, backbone, BatchNorm):\n",
    "    return Decoder(num_classes, backbone, BatchNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWIsXVu3Kg5R"
   },
   "outputs": [],
   "source": [
    "# class deeplabv3(nn.Module):\n",
    "#     def __init__(self, input_channels=1, output_channels=2):\n",
    "#         super(deeplabv3, self).__init__()\n",
    "#         self.resnet = ResNet_50(in_channels=input_channels)\n",
    "#         self.aspp = ASSP(in_channels=2048, final_out_channels=output_channels)\n",
    "#         self.conv = nn.Conv2d(in_channels=2, out_channels=output_channels, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         _, _, h, w = x.shape\n",
    "#         x = self.resnet(x)  # Output should be [batch_size, 2048, H/32, W/32]RuntimeError: Given groups=1, weight of size [256, 2048, 1, 1], expected input[2, 1024, 32, 32] to have 2048 channels, but got 1024 channels instead, 32, 32] to have 2048 channels, but got 1024 channels instead\n",
    "#         x = self.aspp(x)\n",
    "#         x = self.conv(x)\n",
    "#         x = F.interpolate(x, size=(h, w), mode='bilinear', align_corners=True)\n",
    "#         return x\n",
    "\n",
    "\n",
    "\n",
    "class deeplabv3_encoder_decoder(nn.Module):\n",
    "    def __init__(self, input_channels=1, output_channels=2):\n",
    "        super(deeplabv3_encoder_decoder, self).__init__()\n",
    "        self.resnet = ResNet_50(in_channels=input_channels)\n",
    "        self.aspp = ASSP(in_channels=2048, final_out_channels=1024)\n",
    "\n",
    "        # Decoder layers\n",
    "        # self.decoder = nn.Sequential(\n",
    "        #     nn.Conv2d(2, 64, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.BatchNorm2d(64),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Conv2d(64, output_channels, kernel_size=3, stride=1, padding=1)\n",
    "        # )\n",
    "    \n",
    "        self.decoder = nn.Sequential(\n",
    "                nn.ConvTranspose2d(1024, 512, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                nn.BatchNorm2d(512),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.ConvTranspose2d(64, 2, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                # nn.BatchNorm2d(32),\n",
    "                # nn.ReLU(inplace=True),\n",
    "                # nn.ConvTranspose2d(32, 2, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                # nn.Sigmoid()  # Assuming the input images are normalized between 0 and 1\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, _, h, w = x.shape\n",
    "        x = self.resnet(x)  # Output should be [batch_size, 2048, H/32, W/32]\n",
    "        x = self.aspp(x)\n",
    "        # x = F.interpolate(x, size=(h, w), mode='bilinear', align_corners=True)  # Upsample\n",
    "        # print(x.shape)\n",
    "        x = self.decoder(x)  # Decode\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M-6MBryvdFZR",
    "outputId": "35685355-1b45-4d9e-c739-5bfb4e81a479"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "model = deeplabv3_encoder_decoder().to(\"cuda\")\n",
    "\n",
    "summary(model, input_size=(1, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WI4AVijkhF9K"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Your main code here\n",
    "# ...\n",
    "\n",
    "# Clear unused variables\n",
    "# del variable1, variable2, variable3\n",
    "\n",
    "# Manually run garbage collection\n",
    "gc.collect()\n",
    "\n",
    "# Clear GPU cache if using PyTorch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOD215Q2ONlf"
   },
   "outputs": [],
   "source": [
    "class PatchDiscriminator(nn.Module):\n",
    "    def __init__(self, input_c, num_filters=64, n_down=3):\n",
    "        super().__init__()\n",
    "        model = [self.get_layers(input_c, num_filters, norm=False)]\n",
    "        model += [\n",
    "            self.get_layers(\n",
    "                num_filters * 2**i,\n",
    "                num_filters * 2 ** (i + 1),\n",
    "                s=1 if i == (n_down - 1) else 2,\n",
    "            )\n",
    "            for i in range(n_down)\n",
    "        ]  # the 'if' statement is taking care of not using\n",
    "        # stride of 2 for the last block in this loop\n",
    "        model += [\n",
    "            self.get_layers(num_filters * 2**n_down, 1, s=1, norm=False, act=False)\n",
    "        ]  # Make sure to not use normalization or\n",
    "        # activation for the last layer of the model\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def get_layers(\n",
    "        self, ni, nf, k=4, s=2, p=1, norm=True, act=True\n",
    "    ):  # when needing to make some repeatitive blocks of layers,\n",
    "        layers = [\n",
    "            nn.Conv2d(ni, nf, k, s, p, bias=not norm)\n",
    "        ]  # it's always helpful to make a separate method for that purpose\n",
    "        if norm:\n",
    "            layers += [nn.BatchNorm2d(nf)]\n",
    "        if act:\n",
    "            layers += [nn.LeakyReLU(0.2, True)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bg8XsiQ9idGE"
   },
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, gan_mode=\"vanilla\", real_label=1.0, fake_label=0.0):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"real_label\", torch.tensor(real_label))\n",
    "        self.register_buffer(\"fake_label\", torch.tensor(fake_label))\n",
    "        if gan_mode == \"vanilla\":\n",
    "            self.loss = nn.BCEWithLogitsLoss()\n",
    "        elif gan_mode == \"lsgan\":\n",
    "            self.loss = nn.MSELoss()\n",
    "\n",
    "    def get_labels(self, preds, target_is_real):\n",
    "        if target_is_real:\n",
    "            labels = self.real_label\n",
    "        else:\n",
    "            labels = self.fake_label\n",
    "        return labels.expand_as(preds)\n",
    "\n",
    "    def __call__(self, preds, target_is_real):\n",
    "        labels = self.get_labels(preds, target_is_real)\n",
    "        loss = self.loss(preds, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4BzcTrADP3Fg"
   },
   "outputs": [],
   "source": [
    "def init_weights(net, init=\"norm\", gain=0.02):\n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, \"weight\") and \"Conv\" in classname:\n",
    "            if init == \"norm\":\n",
    "                nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n",
    "            elif init == \"xavier\":\n",
    "                nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
    "            elif init == \"kaiming\":\n",
    "                nn.init.kaiming_normal_(m.weight.data, a=0, mode=\"fan_in\")\n",
    "\n",
    "            if hasattr(m, \"bias\") and m.bias is not None:\n",
    "                nn.init.constant_(m.bias.data, 0.0)\n",
    "        elif \"BatchNorm2d\" in classname:\n",
    "            nn.init.normal_(m.weight.data, 1.0, gain)\n",
    "            nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    net.apply(init_func)\n",
    "    print(f\"model initialized with {init} initialization\")\n",
    "    return net\n",
    "\n",
    "\n",
    "def init_model(model, device):\n",
    "    model = model.to(device)\n",
    "    model = init_weights(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mptSdd_qP5Wb"
   },
   "outputs": [],
   "source": [
    "class MainModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, net_G=None, lr_G=2e-4, lr_D=2e-4, beta1=0.5, beta2=0.999, lambda_L1=100.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.lambda_L1 = lambda_L1\n",
    "\n",
    "        if net_G is None:\n",
    "            self.net_G = init_model(\n",
    "                deeplabv3_encoder_decoder(),\n",
    "                self.device\n",
    "            )\n",
    "        else:\n",
    "            self.net_G = net_G.to(self.device)\n",
    "\n",
    "        self.net_D = init_model(\n",
    "            PatchDiscriminator(input_c=3, num_filters=64, n_down=3),\n",
    "            self.device\n",
    "        )\n",
    "\n",
    "        self.GANcriterion = GANLoss(gan_mode=\"vanilla\").to(self.device)\n",
    "        self.L1criterion = nn.L1Loss()\n",
    "        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
    "        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
    "\n",
    "    def set_requires_grad(self, model, requires_grad=True):\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = requires_grad\n",
    "\n",
    "    def setup_input(self, data):\n",
    "        self.L = data[\"L\"].to(self.device)\n",
    "        self.ab = data[\"ab\"].to(self.device)\n",
    "\n",
    "    def forward(self):\n",
    "        self.fake_color = self.net_G(self.L)\n",
    "\n",
    "    def backward_D(self):\n",
    "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
    "        fake_preds = self.net_D(fake_image.detach())\n",
    "        self.loss_D_fake = self.GANcriterion(fake_preds, False)\n",
    "        real_image = torch.cat([self.L, self.ab], dim=1)\n",
    "        real_preds = self.net_D(real_image)\n",
    "        self.loss_D_real = self.GANcriterion(real_preds, True)\n",
    "        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n",
    "        self.loss_D.backward()\n",
    "\n",
    "    def backward_G(self):\n",
    "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
    "        fake_preds = self.net_D(fake_image)\n",
    "        self.loss_G_GAN = self.GANcriterion(fake_preds, True)\n",
    "        self.loss_G_L1 = self.L1criterion(self.fake_color, self.ab) * self.lambda_L1\n",
    "        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n",
    "        self.loss_G.backward()\n",
    "\n",
    "    def optimize(self):\n",
    "        self.forward()\n",
    "        self.net_D.train()\n",
    "        self.set_requires_grad(self.net_D, True)\n",
    "        self.opt_D.zero_grad()\n",
    "        self.backward_D()\n",
    "        self.opt_D.step()\n",
    "\n",
    "        self.net_G.train()\n",
    "        self.set_requires_grad(self.net_D, False)\n",
    "        self.opt_G.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.opt_G.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIzF5WVdXhxn"
   },
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.count, self.avg, self.sum = [0.0] * 3\n",
    "\n",
    "    def update(self, val, count=1):\n",
    "        self.count += count\n",
    "        self.sum += count * val\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def create_loss_meters():\n",
    "    loss_D_fake = AverageMeter()\n",
    "    loss_D_real = AverageMeter()\n",
    "    loss_D = AverageMeter()\n",
    "    loss_G_GAN = AverageMeter()\n",
    "    loss_G_L1 = AverageMeter()\n",
    "    loss_G = AverageMeter()\n",
    "\n",
    "    return {\n",
    "        \"loss_D_fake\": loss_D_fake,\n",
    "        \"loss_D_real\": loss_D_real,\n",
    "        \"loss_D\": loss_D,\n",
    "        \"loss_G_GAN\": loss_G_GAN,\n",
    "        \"loss_G_L1\": loss_G_L1,\n",
    "        \"loss_G\": loss_G,\n",
    "    }\n",
    "\n",
    "\n",
    "def update_losses(model, loss_meter_dict, count):\n",
    "    for loss_name, loss_meter in loss_meter_dict.items():\n",
    "        loss = getattr(model, loss_name)\n",
    "        loss_meter.update(loss.item(), count=count)\n",
    "\n",
    "\n",
    "def lab_to_rgb(L, ab):\n",
    "    \"\"\"\n",
    "    Takes a batch of images\n",
    "    \"\"\"\n",
    "\n",
    "    L = (L + 1.0) * 50.0\n",
    "    ab = ab * 110.0\n",
    "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
    "    rgb_imgs = []\n",
    "    for img in Lab:\n",
    "        img_rgb = lab2rgb(img)\n",
    "        rgb_imgs.append(img_rgb)\n",
    "    return np.stack(rgb_imgs, axis=0)\n",
    "\n",
    "\n",
    "def visualize(model, data, save=True):\n",
    "    print(\"Started Visualizing\")\n",
    "    model.net_G.eval()\n",
    "    with torch.no_grad():\n",
    "        model.setup_input(data)\n",
    "        model.forward()\n",
    "    model.net_G.train()\n",
    "    fake_color = model.fake_color.detach()\n",
    "    real_color = model.ab\n",
    "    L = model.L\n",
    "    fake_imgs = lab_to_rgb(L, fake_color)\n",
    "    real_imgs = lab_to_rgb(L, real_color)\n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    for i in range(5):\n",
    "        ax = plt.subplot(3, 5, i + 1)\n",
    "        ax.imshow(L[i][0].cpu(), cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "        ax = plt.subplot(3, 5, i + 1 + 5)\n",
    "        ax.imshow(fake_imgs[i])\n",
    "        ax.axis(\"off\")\n",
    "        ax = plt.subplot(3, 5, i + 1 + 10)\n",
    "        ax.imshow(real_imgs[i])\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "    if save:\n",
    "        fig.savefig(f\"colorization_{time.time()}.png\")\n",
    "\n",
    "\n",
    "def log_results(loss_meter_dict):\n",
    "    for loss_name, loss_meter in loss_meter_dict.items():\n",
    "        print(f\"{loss_name}: {loss_meter.avg:.5f}\")\n",
    "\n",
    "\n",
    "def create_lab_tensors(image):\n",
    "    \"\"\"\n",
    "    This function receives an image path or a direct image input and creates a dictionary of L and ab tensors.\n",
    "    Args:\n",
    "    - image: either a path to the image file or a direct image input.\n",
    "    Returns:\n",
    "    - lab_dict: dictionary containing the L and ab tensors.\n",
    "    \"\"\"\n",
    "    if isinstance(image, str):\n",
    "        # Open the image and convert it to RGB format\n",
    "        img = Image.open(image).convert(\"RGB\")\n",
    "    else:\n",
    "        img = image.convert(\"RGB\")\n",
    "\n",
    "    custom_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((INPUT_SHAPE, INPUT_SHAPE), Image.BICUBIC),\n",
    "            transforms.RandomHorizontalFlip(),  # A little data augmentation!\n",
    "        ]\n",
    "    )\n",
    "    img = custom_transforms(img)\n",
    "    img = np.array(img)\n",
    "    img_lab = rgb2lab(img).astype(\"float32\")  # Converting RGB to L*a*b\n",
    "    img_lab = transforms.ToTensor()(img_lab)\n",
    "    L = img_lab[[0], ...] / 50.0 - 1.0  # Between -1 and 1\n",
    "    L = L.unsqueeze(0)\n",
    "    ab = img_lab[[1, 2], ...] / 110.0  # Between -1 and 1\n",
    "    return {\"L\": L, \"ab\": ab}\n",
    "\n",
    "\n",
    "def predict_and_visualize_single_image(model, data, save=True):\n",
    "    model.net_G.eval()\n",
    "    with torch.no_grad():\n",
    "        model.setup_input(data)\n",
    "        model.forward()\n",
    "    fake_color = model.fake_color.detach()\n",
    "    L = model.L\n",
    "    fake_imgs = lab_to_rgb(L, fake_color)\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    axs[0].imshow(L[0][0].cpu(), cmap=\"gray\")\n",
    "    axs[0].set_title(\"Grey Image\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    axs[1].imshow(fake_imgs[0])\n",
    "    axs[1].set_title(\"Colored Image\")\n",
    "    axs[1].axis(\"off\")\n",
    "    plt.show()\n",
    "    if save:\n",
    "        fig.savefig(f\"colorization_{time.time()}.png\")\n",
    "\n",
    "\n",
    "def predict_color(model, image, save=False):\n",
    "    \"\"\"\n",
    "    This function receives an image path or a direct image input and creates a dictionary of L and ab tensors.\n",
    "    Args:\n",
    "    - model : Pytorch Gray Scale to Colorization Model\n",
    "    - image: either a path to the image file or a direct image input.\n",
    "    \"\"\"\n",
    "    data = create_lab_tensors(image)\n",
    "    predict_and_visualize_single_image(model, data, save)\n",
    "\n",
    "\n",
    "def predict_and_return_image(image):\n",
    "    data = create_lab_tensors(image)\n",
    "    model.net_G.eval()\n",
    "    with torch.no_grad():\n",
    "        model.setup_input(data)\n",
    "        model.forward()\n",
    "    fake_color = model.fake_color.detach()\n",
    "    L = model.L\n",
    "    fake_imgs = lab_to_rgb(L, fake_color)\n",
    "    return fake_imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ufGalPu1XlTi"
   },
   "outputs": [],
   "source": [
    "model_path = \"./ImageColorizationModel.pth\"\n",
    "\n",
    "\n",
    "def save_model(model, file_path):\n",
    "    \"\"\"\n",
    "    Save PyTorch model to file.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): PyTorch model to save.\n",
    "        file_path (str): File path to save the model to.\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), file_path)\n",
    "\n",
    "\n",
    "def load_model(model_class, file_path):\n",
    "    \"\"\"\n",
    "    Load PyTorch model from file.\n",
    "\n",
    "    Args:\n",
    "        model_class (torch.nn.Module): PyTorch model class to load.\n",
    "        file_path (str): File path to load the model from.\n",
    "\n",
    "    Returns:\n",
    "        model (torch.nn.Module): Loaded PyTorch model.\n",
    "    \"\"\"\n",
    "    model = model_class()\n",
    "    model.load_state_dict(torch.load(file_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3ht6AgESXoNX",
    "outputId": "63b4057c-d4d9-4e26-9052-3191108edfc4"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train_model(model, train_dl, epochs, display_every=200):\n",
    "    data = next(\n",
    "        iter(testdl)\n",
    "    )  # getting a batch for visualizing the model output after fixed intrvals\n",
    "    print(\"started\")\n",
    "    for e in range(epochs):\n",
    "        # print(\"Inprogress\")\n",
    "        loss_meter_dict = (\n",
    "            create_loss_meters()\n",
    "        )  # function returing a dictionary of objects to\n",
    "        i = 0  # log the losses of the complete network\n",
    "        for data in tqdm(train_dl):\n",
    "            # print(\"tqdm\")\n",
    "            model.setup_input(data)\n",
    "            model.optimize()\n",
    "            update_losses(\n",
    "                model, loss_meter_dict, count=data[\"L\"].size(0)\n",
    "            )  # function updating the log objects\n",
    "            i += 1\n",
    "            if i % display_every == 0:\n",
    "                print(f\"\\nEpoch {e+1}/{epochs}\")\n",
    "                print(f\"Iteration {i}/{len(train_dl)}\")\n",
    "                log_results(loss_meter_dict)  # function to print out the losses\n",
    "                visualize(\n",
    "                    model, data, save=False\n",
    "                )  # function displaying the model's outputs\n",
    "        save_model(model=model, file_path=f\"ImageColorizationModel{e}.pth\")\n",
    "                \n",
    "\n",
    "\n",
    "model = None\n",
    "if not os.path.exists(model_path):\n",
    "    print(\"Model not find\")\n",
    "    model = MainModel()\n",
    "    train_model(model, traindl, 100)\n",
    "    save_model(model=model, file_path=\"ImageColorizationModel.pth\")\n",
    "else:\n",
    "    model = load_model(model_class=MainModel, file_path=model_path)\n",
    "    print(\"Model Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
